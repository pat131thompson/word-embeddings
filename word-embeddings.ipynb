{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02aaad15",
   "metadata": {},
   "source": [
    "<h4>Word Embeddings</h4>\n",
    "\n",
    "Word embeddings are a way to represent words as numbers that computers can understand and work with. \n",
    "\n",
    "The key idea is simple: words with similar meanings should be represented by similar numbers.\n",
    "\n",
    "Think of it like a map where words are placed as points - words that mean similar things (like \"cat\" and \"dog\") end up close to each other, while unrelated words (like \"cat\" and \"algebra\") are far apart.\n",
    "\n",
    "These systems learn by looking at huge amounts of text and noticing which words appear together frequently. For example, words like \"king\" and \"queen\" often appear in similar sentences, so the system learns they're related.\n",
    "\n",
    "Below are examples of the GloVe model which takes an approach of creating a big table of how often words appear together, then using mathematical techniques to turn that into word representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b6ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the gensim library to work with word vectors\n",
    "# The \"as api\" import allows us to easily download pre-trained models\n",
    "# KeyedVectors is used to handle the word vectors efficiently \n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2aec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "\n",
      "fasttext-wiki-news-subwords-300\n",
      "conceptnet-numberbatch-17-06-300\n",
      "word2vec-ruscorpora-300\n",
      "word2vec-google-news-300\n",
      "glove-wiki-gigaword-50\n",
      "glove-wiki-gigaword-100\n",
      "glove-wiki-gigaword-200\n",
      "glove-wiki-gigaword-300\n",
      "glove-twitter-25\n",
      "glove-twitter-50\n",
      "glove-twitter-100\n",
      "glove-twitter-200\n",
      "__testing_word2vec-matrix-synopsis\n"
     ]
    }
   ],
   "source": [
    "# List all available models from the gensim downloader\n",
    "\n",
    "print(\"Available models:\\n\")\n",
    "for model_name in api.info()['models'].keys():\n",
    "    print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d55af0",
   "metadata": {},
   "source": [
    "<h4>GloVe embeddings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee42e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we load a GloVe vectors pre-trained model (trained on Twitter data)\n",
    "\n",
    "model = api.load(\"glove-twitter-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8184c769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vector for 'abuse':\n",
      " [ 0.60233   0.76993  -0.89615  -0.15807  -0.21837  -0.009611  0.31435\n",
      " -0.7212    0.18842  -0.20418   0.5714   -0.68694  -3.2285   -0.1543\n",
      "  0.57321   0.66187  -0.67019  -1.0092    0.033162 -0.23652  -0.18133\n",
      "  0.24384   0.40323  -0.10941  -0.17483   0.21203   0.53417   0.69763\n",
      " -0.61553   0.53514   0.10736  -0.56608  -0.12903   0.035331  0.19674\n",
      " -0.36697  -1.2568    0.085889 -0.59497  -2.2233    0.57036  -1.3173\n",
      "  0.25104  -0.24124   0.47565   0.17862   0.11298   0.36407  -0.027958\n",
      " -0.74695 ]\n"
     ]
    }
   ],
   "source": [
    "# Display the vector for the word \"abuse\"\n",
    "print(\"\\nVector for 'abuse':\\n\", model['abuse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbee034e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrest: 0.8591\n",
      "rape: 0.8546\n",
      "murder: 0.8462\n",
      "alleged: 0.8449\n",
      "harassment: 0.8404\n",
      "charges: 0.8384\n",
      "appeal: 0.8315\n",
      "violence: 0.8252\n",
      "terrorism: 0.8232\n",
      "cruelty: 0.8197\n",
      "investigation: 0.8146\n",
      "rights: 0.8108\n",
      "torture: 0.7982\n",
      "terrorist: 0.7972\n",
      "victim: 0.7938\n",
      "threatening: 0.7902\n",
      "execution: 0.7893\n",
      "weapons: 0.7868\n",
      "crime: 0.7867\n",
      "military: 0.7846\n"
     ]
    }
   ],
   "source": [
    "# Looking up a words associated to Domestic Violence (physical) in the model and identifying similar words \n",
    "\n",
    "similar_words = model.most_similar(positive = [\"abuse\", \"domestic\", \"assault\"], topn = 20)\n",
    "\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8294db2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physical: 0.8272\n",
      "critical: 0.8230\n",
      "illness: 0.8194\n",
      "harm: 0.8027\n",
      "depression: 0.7956\n",
      "causes: 0.7914\n",
      "issues: 0.7846\n",
      "violent: 0.7822\n",
      "torture: 0.7819\n",
      "lack: 0.7803\n",
      "anxiety: 0.7740\n",
      "substance: 0.7738\n",
      "anger: 0.7725\n",
      "significant: 0.7699\n",
      "human: 0.7689\n",
      "causing: 0.7679\n",
      "suffering: 0.7676\n",
      "danger: 0.7647\n",
      "common: 0.7609\n",
      "situation: 0.7600\n"
     ]
    }
   ],
   "source": [
    "# Looking up a words associated to Domestic Violence (non-physical) in the model and identifying similar words \n",
    "\n",
    "similar_words = model.most_similar(positive=[\"emotional\", \"abuse\", \"psychological\"], topn=20)\n",
    "\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa050f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrest: 0.7410\n",
      "abortion: 0.7244\n",
      "harassment: 0.7242\n",
      "murder: 0.7111\n",
      "appeal: 0.6977\n",
      "blasphemy: 0.6950\n",
      "abuse: 0.6909\n",
      "rapist: 0.6902\n",
      "punishment: 0.6898\n",
      "victim: 0.6792\n",
      "judge: 0.6678\n",
      "terrorist: 0.6666\n",
      "violence: 0.6662\n",
      "innocent: 0.6600\n",
      "marriage: 0.6595\n",
      "laws: 0.6594\n",
      "sandusky: 0.6593\n",
      "alleged: 0.6560\n",
      "anti-gay: 0.6558\n",
      "defend: 0.6548\n"
     ]
    }
   ],
   "source": [
    "# Looking for analogous words.\n",
    "\n",
    "analogous = model.most_similar(positive=[\"rape\", \"assault\"], negative=[\"theft\"], topn = 20)\n",
    "for word, analogy in analogous:\n",
    "    print(f\"{word}: {analogy:.4f}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8895c0f0",
   "metadata": {},
   "source": [
    "ELMo was more advanced - instead of giving each word one fixed representation, it creates different representations depending on how the word is used in each sentence.\n",
    "The main breakthrough was showing that computers could learn meaningful relationships between words just by reading lots of text, without anyone having to explicitly teach them what words mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b26c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# ELMo requires TensorFlow and TensorFlow Hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained ELMo model from TensorFlow Hub\n",
    "print(\"Loading ELMo model...\")\n",
    "elmo = hub.load(\"https://tfhub.dev/google/elmo/3\")\n",
    "\n",
    "def get_elmo_embeddings(sentences):\n",
    "    \"\"\"\n",
    "    Get ELMo embeddings for a list of sentences\n",
    "    Returns the default representation (mean of all layers)\n",
    "    \"\"\"\n",
    "    # ELMo expects a list of sentences\n",
    "    embeddings = elmo(sentences)\n",
    "    \n",
    "    # ELMo returns multiple representations, we'll use the default one\n",
    "    return embeddings[\"default\"].numpy()\n",
    "\n",
    "def find_similar_context_words(target_sentences, candidate_sentences, top_n=5):\n",
    "    \"\"\"\n",
    "    Find sentences with similar context to target sentences\n",
    "    \"\"\"\n",
    "    # Get embeddings for all sentences\n",
    "    all_sentences = target_sentences + candidate_sentences\n",
    "    embeddings = get_elmo_embeddings(all_sentences)\n",
    "    \n",
    "    # Split embeddings\n",
    "    target_embeddings = embeddings[:len(target_sentences)]\n",
    "    candidate_embeddings = embeddings[len(target_sentences):]\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity(target_embeddings, candidate_embeddings)\n",
    "    \n",
    "    # Find most similar for each target\n",
    "    results = []\n",
    "    for i, target_sentence in enumerate(target_sentences):\n",
    "        # Get similarity scores for this target\n",
    "        scores = similarities[i]\n",
    "        \n",
    "        # Get top similar candidates\n",
    "        top_indices = np.argsort(scores)[::-1][:top_n]\n",
    "        \n",
    "        similar_contexts = []\n",
    "        for idx in top_indices:\n",
    "            similar_contexts.append({\n",
    "                'sentence': candidate_sentences[idx],\n",
    "                'similarity': scores[idx]\n",
    "            })\n",
    "        \n",
    "        results.append({\n",
    "            'target': target_sentence,\n",
    "            'similar': similar_contexts\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage similar to your GloVe code\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ELMo Context-Dependent Word Embeddings Demo\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define sentences containing words related to domestic violence (physical)\n",
    "physical_violence_sentences = [\n",
    "    \"The abuse was physical and left visible marks\",\n",
    "    \"Domestic violence includes physical assault and battery\",\n",
    "    \"Physical abuse can cause serious injury\"\n",
    "]\n",
    "\n",
    "# Define candidate sentences for comparison\n",
    "candidate_sentences = [\n",
    "    \"The abuse of power was evident in the political scandal\",\n",
    "    \"Drug abuse is a serious health problem\",\n",
    "    \"Emotional abuse can be just as damaging as physical violence\",\n",
    "    \"The assault was reported to the police immediately\",\n",
    "    \"Domestic disputes often escalate to violence\",\n",
    "    \"Physical therapy helped with the injury recovery\",\n",
    "    \"The battery in my phone needs charging\",\n",
    "    \"Mental health support is crucial for abuse survivors\",\n",
    "    \"Violence in movies has increased over the years\",\n",
    "    \"The physical examination revealed no injuries\"\n",
    "]\n",
    "\n",
    "print(\"\\nFinding sentences with similar contexts to physical violence...\")\n",
    "results = find_similar_context_words(physical_violence_sentences, candidate_sentences, top_n=3)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"\\nTarget: '{result['target']}'\")\n",
    "    print(\"Most similar contexts:\")\n",
    "    for i, similar in enumerate(result['similar'], 1):\n",
    "        print(f\"  {i}. '{similar['sentence']}' (similarity: {similar['similarity']:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Demonstrating Context Sensitivity\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show how the same word gets different embeddings in different contexts\n",
    "context_examples = [\n",
    "    \"The financial abuse involved stealing money\",\n",
    "    \"The child abuse case was heartbreaking\",\n",
    "    \"The substance abuse program helped many people\",\n",
    "    \"The verbal abuse continued for years\"\n",
    "]\n",
    "\n",
    "print(\"\\nGetting embeddings for different contexts of 'abuse':\")\n",
    "embeddings = get_elmo_embeddings(context_examples)\n",
    "\n",
    "# Calculate similarities between different uses of \"abuse\"\n",
    "context_similarities = cosine_similarity(embeddings)\n",
    "\n",
    "print(\"\\nSimilarity matrix between different contexts:\")\n",
    "print(\"Sentences:\")\n",
    "for i, sentence in enumerate(context_examples):\n",
    "    print(f\"{i+1}. {sentence}\")\n",
    "\n",
    "print(f\"\\nSimilarity Matrix:\")\n",
    "print(\"     \", end=\"\")\n",
    "for i in range(len(context_examples)):\n",
    "    print(f\"  {i+1:>6}\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i in range(len(context_examples)):\n",
    "    print(f\"{i+1:>2}. \", end=\"\")\n",
    "    for j in range(len(context_examples)):\n",
    "        print(f\"  {context_similarities[i][j]:>6.3f}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Word Analogy with Context\")\n",
    "print(\"=\"*60)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "word-embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
